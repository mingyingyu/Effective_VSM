{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import check_pairwise_arrays\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the query vector\n",
    "def createQueryVector(query, inverted_index):\n",
    "    '''\n",
    "    creates the query vector.\n",
    "    \n",
    "    query: list of unique terms of the query\n",
    "    inverted_index: the regular inverted index\n",
    "    '''\n",
    "    rtn = np.zeros(len(inverted_index))\n",
    "    for term in query:\n",
    "        #print(term)\n",
    "        try: \n",
    "            pos = list(inverted_index.keys()).index(term)\n",
    "            rtn[pos] = 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if (np.sum(rtn)==0):\n",
    "        raise ValueError('None of the search terms is part of the collection.')\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedure that takes one doc and outputs the corresponding vector.\n",
    "def createVector(doc,inverted_index,idf):\n",
    "    '''\n",
    "    procedure takes a document and outputs the corresponding vector containing tf-idf values. The output is not normalised.\n",
    "    \n",
    "    doc: preprocessed document as a list of unique terms\n",
    "    inverted_index \n",
    "    idf\n",
    "    '''\n",
    "    terms, tf = termFrequencies(doc)\n",
    "    #create vector\n",
    "    rtn = np.zeros(len(inverted_index))\n",
    "    for i in range(len(terms)): # for loop with ints running through the bag of words of doc\n",
    "        term = terms[i] # the term at position i\n",
    "        #find correct position in vector\n",
    "        pos = list(inverted_index.keys()).index(term)\n",
    "        #insert tf-idf of term\n",
    "        rtn[pos] = idf[term] * tf[i]\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieveBool(query,inverted_index): \n",
    "    '''\n",
    "    boolean retrieval with query or-ed to get initial set\n",
    "    \n",
    "    query as bag of words representation preprocessed (as a list!)\n",
    "    '''\n",
    "    \n",
    "    rtn = []\n",
    "    for term in query:\n",
    "        #retrieve posting list\n",
    "        try:\n",
    "            help = inverted_index[term]\n",
    "            rtn += [i[0] for i in help]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    rtn = list(set(rtn)) #eliminate all duplicates\n",
    "    return sorted(rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine ranking\n",
    "def retrieveCosine(query,inverted_index,idf,collectionAsDataframe: pd.DataFrame,amount=100):\n",
    "    '''basic slow cosine retrieval\n",
    "    \n",
    "    query    as preprocessed list of unique terms\n",
    "    inverted_index\n",
    "    collectionAsDataframe   as preprocessed pandas dataframe'''\n",
    "    #split collection in id column and collection as list\n",
    "    collection=list(collectionAsDataframe['text'])\n",
    "    docIDs = list(collectionAsDataframe['id'])\n",
    "    \n",
    "    #get all relevant docs with boolean retrieval\n",
    "    boolResult = retrieveBool(query,inverted_index)\n",
    "    #get vectors for all docs\n",
    "    docVecs = []\n",
    "    print(len(boolResult))\n",
    "    for d in boolResult:\n",
    "        docVecs.append(createVector(collection[d],inverted_index,idf))\n",
    "#         if i % 100 = 0:\n",
    "#             print(i)\n",
    "#     docVecs = [createVector(d,inverted_index,collection,idf) for d in boolResult]\n",
    "    #get query vector\n",
    "    \n",
    "    queryVec = [createQueryVector(query,inverted_index)]\n",
    "    #rank them\n",
    "    results = {}\n",
    "    for i in range(len(docVecs)):\n",
    "        v = [docVecs[i]]\n",
    "        #compute cosine\n",
    "        cos = cosine_similarity(queryVec,v)\n",
    "        #save\n",
    "        results[docIDs[boolResult[i]]]=cos[0][0]\n",
    "    #sort output and cut to amount\n",
    "    rtn = sorted(results.items(), key=lambda kv: kv[1],reverse = True)\n",
    "    if(len(rtn) > amount):\n",
    "        rtn = rtn[0:amount]\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testQuery = ['vascular','anxious']\n",
    "invalidQuery = ['asdfhjahfd','wieuriowuer']\n",
    "#retrieveCosine(invalidQuery)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for Mingying, don't run.\n",
    "\n",
    "#doc =inverted_index[0]\n",
    "#doc = np.unique(doc)\n",
    "#cosineSimilarity(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
