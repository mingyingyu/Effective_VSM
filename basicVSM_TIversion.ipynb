{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import check_pairwise_arrays\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an adaption of the basic VSM model. It resembles part of an old version of the file which is used as a resource file for the TieredIndex as it doesn't work correctly with the latest version of the basic VSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the query vector\n",
    "def createQueryVectorTI(query, inverted_index):\n",
    "    '''\n",
    "    creates the query vector.\n",
    "    \n",
    "    query: list of unique terms of the query\n",
    "    inverted_index: the regular inverted index\n",
    "    '''\n",
    "    rtn = np.zeros(len(inverted_index))\n",
    "    for term in query:\n",
    "        #print(term)\n",
    "        try: \n",
    "            pos = list(inverted_index.keys()).index(term)\n",
    "            rtn[pos] = 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if (np.sum(rtn)==0):\n",
    "        raise ValueError('None of the search terms is part of the collection.')\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedure that takes one doc and outputs the corresponding vector.\n",
    "def createVectorTI(d,inverted_index,collection,idf): #d is the index of a document\n",
    "    #look up, bag of words of d\n",
    "    doc = collection[d]\n",
    "    #compute term frequency\n",
    "    f = np.unique(doc,return_counts=True)\n",
    "    max_f = np.max(f[1])\n",
    "    tf = 1+np.log(f[1])\n",
    "    tf = tf/(1 + np.log(max_f))\n",
    "    #create vector\n",
    "    rtn = np.zeros(len(inverted_index))\n",
    "    for i in range(len(f[0])): # for loop with ints running through the bag of words of doc\n",
    "        term = f[0][i] # the term at position i\n",
    "        #find correct position in vector\n",
    "        if term not in inverted_index:\n",
    "            continue\n",
    "        pos = list(inverted_index.keys()).index(term)\n",
    "        #insert tf-idf of term\n",
    "        rtn[pos] = idf[term] * tf[i]\n",
    "    return rtn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
